{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generate a csv file containing the statistical analysis of time series generated by gLV models with or without maximal capacity.\n",
    "\n",
    "\n",
    "You can choose to scan over immigration rates, connectance of the interaction matrices, the level of noise and the value of the maximal capacity (set np.inf for no maximal capacity). \n",
    "\n",
    "You need to specify how many similations per choice of parameters (ie choice of connectance, noise level, etc). This is set in N_repeats. For gLV, you need also to specify the threshold for extinction, default value is $10^{-6}$.\n",
    "\n",
    "Rem: IBMs can be analysed similarty see testing_scan.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdebuyl/heavy_tails/python_codes/piecewise_normalizations.py:50: MatplotlibDeprecationWarning: default base may change from np.e to 10.  To suppress this warning specify the base keyword argument.\n",
      "  SymLogNorm.__init__(self, linthresh, linscale=0.01, vmin=self._lower, vmax=self._upper)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import functools\n",
    "import python_codes.Timeseries_glv as glv \n",
    "import python_codes.Timeseries_ibm as ibm \n",
    "from python_codes.noise_parameters import NOISE\n",
    "from python_codes.models import MODEL\n",
    "from python_codes.heavytails import fit_heavytail\n",
    "from python_codes.neutrality_analysis import BrayCurtis, BrayCurtis_neutrality, KullbackLeibler, KullbackLeibler_neutrality, JensenShannon\n",
    "from python_codes.variation import variation_coefficient, JS\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     9,
     34,
     49,
     73,
     78,
     184,
     197,
     207,
     261,
     292
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "noise_implementation = NOISE.LANGEVIN_LINEAR  # CONSTANT\n",
    "\n",
    "if debug:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from python_codes.timeseries_plotting import PlotTimeseries\n",
    "    from python_codes.heavytails import plot_heavytail\n",
    "\n",
    "def random_parameter_set(S, connectance=0.3, minint=-0.5, maxint=0.5,\n",
    "                         minmigration=0.4, maxmigration=0.4,\n",
    "                         minextinction=0.5, maxextinction=0.5, growth_rate=1.5):\n",
    "    \"\"\" Return a set of random parameters to generate glv time series \"\"\"\n",
    "\n",
    "    # Interaction matrix\n",
    "    interaction = np.random.uniform(minint, maxint, [S, S])\n",
    "\n",
    "    # Impose connectance: set interaction matrix elements to zero such that the percentage of non-zero elements\n",
    "    # is equal to the connectance\n",
    "    interaction *= np.random.choice([0, 1], interaction.shape, p=[1 - connectance, connectance])\n",
    "\n",
    "    # Self-interaction is -1 for all species.\n",
    "    np.fill_diagonal(interaction, -1.)\n",
    "\n",
    "    # Growth rate is equal for all species (value is growth_rate).\n",
    "    growth_rate = np.full([S, 1], growth_rate)\n",
    "\n",
    "    # Uniform immigration and extinction rates.\n",
    "    immigration = np.random.uniform(minmigration, maxmigration, [S, 1])\n",
    "    extinction = np.random.uniform(minextinction, maxextinction, [S, 1])\n",
    "\n",
    "    return {'interaction_matrix': interaction, 'immigration_rate': immigration,\n",
    "              'extinction_rate': extinction, 'growth_rate': growth_rate}\n",
    "\n",
    "def random_parameter_set_ibm(S, connectance=0.3, minint=-0.5, maxint=0.5,\n",
    "                             minmigration=0.4, maxmigration=0.4,\n",
    "                             minextinction=0.5, maxextinction=0.5, growth_rate=1.5, SIS=[], SISfactor=200):\n",
    "\n",
    "    params = random_parameter_set(S, connectance, minint, maxint,\n",
    "                         minmigration, maxmigration, minextinction, maxextinction, growth_rate)\n",
    "\n",
    "    # Generate strongly-interacting-species (SIS) vector.\n",
    "    SISvector = np.ones(S, dtype=int)\n",
    "    SISvector[SIS] *= SISfactor\n",
    "\n",
    "    params['SISvector'] = SISvector\n",
    "\n",
    "    return params\n",
    "\n",
    "def random_parameter_set_logistic(S, width_growth=1):\n",
    "    # Set growth rates.\n",
    "    if width_growth == 0:\n",
    "        growth_rate = np.ones([S, 1])\n",
    "    else:\n",
    "        growth_rate = stats.lognorm.rvs(loc=0, s=width_growth, size=[S, 1])\n",
    "\n",
    "    # No interactions becauce logistic model\n",
    "    interaction = np.zeros([S, S])\n",
    "\n",
    "    # Calculate and set self-interactions.\n",
    "    if width_growth == 2:\n",
    "        self_int = np.ones(S)\n",
    "    else:\n",
    "        self_int = stats.lognorm.rvs(loc=0, s=np.sqrt(4 - width_growth ** 2), size=S)\n",
    "    np.fill_diagonal(interaction, -self_int)\n",
    "\n",
    "    # No immigration or extinction.\n",
    "    immigration = np.zeros([S, 1])\n",
    "    extinction = np.zeros([S, 1])\n",
    "\n",
    "    return {'interaction_matrix': interaction, 'immigration_rate': immigration,\n",
    "              'extinction_rate': extinction, 'growth_rate': growth_rate}\n",
    "\n",
    "def add_SIS(interaction, SISvector): #not used... \n",
    "    interaction_SIS = interaction * SISvector\n",
    "    np.fill_diagonal(interaction_SIS, np.diag(interaction))\n",
    "    return interaction_SIS\n",
    "\n",
    "def line_statistics(params, model=MODEL.GLV):\n",
    "    \"\"\" Generates a time series with the given parameters and returns a string with all statistical parameters\n",
    "    of this time series.\"\"\"\n",
    "\n",
    "    # Initiate empty line\n",
    "    line = ''\n",
    "\n",
    "    # First simulate without noise to allow system to go to steady state\n",
    "    params_nonoise = params.copy()  # parameters without noise\n",
    "    for noise in ['noise_linear', 'noise_constant']:\n",
    "        if noise in params_nonoise:\n",
    "            params_nonoise[noise] = 0\n",
    "\n",
    "    if model in [MODEL.GLV, MODEL.MAX, MODEL.MAX_IMMI]:\n",
    "        discrete = False\n",
    "\n",
    "        # Find steady state without noise (this is not printing the ss)\n",
    "        ts = glv.Timeseries(params_nonoise, T=250, dt=0.01, tskip=99, model=model)\n",
    "        if debug:\n",
    "            PlotTimeseries(ts.timeseries)\n",
    "\n",
    "        # Determine deterministic stability: stable if less than 10% change for last 50 time points.\n",
    "        \n",
    "        deterministic_stability = (np.max(np.abs((ts.timeseries.iloc[-50, 1:] - ts.timeseries.iloc[-1, 1:]) / ts.timeseries.iloc[-50,\n",
    "                                                                                           1:])) < 0.1)\n",
    "        line += ',%d' % deterministic_stability\n",
    "\n",
    "        # Find steady state with noise\n",
    "        # Set steady state to deterministic steady state\n",
    "        params['initial_condition'] = ts.endpoint.values.astype('float')\n",
    "        ts = glv.Timeseries(params, T=500, dt=0.01, tskip=99, model=model, noise_implementation=noise_implementation)\n",
    "\n",
    "        if False:\n",
    "            PlotTimeseries(ts.timeseries)\n",
    "    elif model == MODEL.IBM:\n",
    "        discrete = True\n",
    "\n",
    "        # Time series to find \"steady state\", transient dynamics\n",
    "        params['initial_condition'] = ibm.Timeseries(params, T=50).endpoint.values.astype('int').flatten()\n",
    "\n",
    "        # Time series for IBM.\n",
    "        ts = ibm.Timeseries(params, T=250)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model: %s\" % model.__name__)\n",
    "\n",
    "    endpoint = ts.endpoint\n",
    "\n",
    "    # Remove species that are \"extinct\", by definition: smaller than 6 orders of magnitude smaller than maximal abundance\n",
    "    col_to_drop = endpoint.index[endpoint.endpoint < threshold * np.max(endpoint.endpoint)] #todo -8\n",
    "\n",
    "    with warnings.catch_warnings(): # Ignore the NAN-warnings when removing species.\n",
    "        warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
    "\n",
    "        endpoint = endpoint.values.astype('float').flatten()\n",
    "\n",
    "        endpoint = endpoint[endpoint > threshold * np.nanmax(endpoint)]\n",
    "\n",
    "    if model in [MODEL.GLV, MODEL.MAX, MODEL.MAX_IMMI]:\n",
    "        ts_trimmed = ts.timeseries.drop(columns=col_to_drop)\n",
    "    elif model == MODEL.IBM:\n",
    "        ts_trimmed = ts.timeseries\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model: %s\" % model.__name__)\n",
    "\n",
    "    # Diversity is number of remaining species.\n",
    "    diversity = len(endpoint)\n",
    "    line += ',%d' % diversity\n",
    "\n",
    "    # Normalized time series.\n",
    "    ts_norm = ts.timeseries.div(\n",
    "        ts.timeseries.loc[:, [col for col in ts.timeseries.columns if col.startswith('species')]].sum(axis=1), axis=0)\n",
    "    ts_norm.time = ts.timeseries.time\n",
    "\n",
    "    # Calculate variation coefficient for time series, and normalized time series.\n",
    "    for tsi in [ts_trimmed, ts_norm]:\n",
    "        params = variation_coefficient(tsi)\n",
    "        for par in params:\n",
    "            line += ',%.3E' % par\n",
    "\n",
    "    # Calculate Jensen Shannon distance.\n",
    "    params_JS = JS(ts_trimmed)\n",
    "    for par in params_JS:\n",
    "        line += ',%.3E' % par\n",
    "\n",
    "    # Calculate parameters for fitting heavy tailed distributions.\n",
    "    for func in ['lognorm', 'pareto', 'powerlaw', 'trunc_powerlaw', 'expon', 'norm']:\n",
    "        params = fit_heavytail(endpoint, func=func, discrete=discrete)\n",
    "\n",
    "        for par in params:\n",
    "            line += ',%.3E' % par\n",
    "\n",
    "    if debug:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        \n",
    "\n",
    "        params = fit_heavytail(endpoint, func='lognorm', discrete=discrete)\n",
    "        plot_heavytail(endpoint, params, func='lognorm', ax=ax, discrete=discrete)\n",
    "        print(\"Width lognorm:\", params[0])\n",
    "        print(\"Stat lognorm:\", params[-2])\n",
    "\n",
    "     \n",
    "        plt.show()\n",
    "    return line\n",
    "\n",
    "def initial_condition(S_, model, max_cap, absent_init):\n",
    "    initcond = np.random.uniform(0, 1, [S_, 1])\n",
    "\n",
    "    if 'MAX' in model.name:\n",
    "        # Rescale initial condition with maximum capacity.\n",
    "        initcond *= min(1., 1. * max_cap / S_)\n",
    "\n",
    "    if absent_init:\n",
    "        # Set random species to zero, they may enter the system through immigration.\n",
    "        initcond *= np.random.choice([0, 1], size=initcond.shape, p=[0.2, 0.8])\n",
    "\n",
    "    return initcond\n",
    "\n",
    "def setup_glv(file, N=10):\n",
    "    \"\"\" Adds header line for gLV time series.\"\"\"\n",
    "\n",
    "    # Fixed parameters for line.\n",
    "    line = 'connectance,immigration,noise,interaction,max_cap' + header_time_series(N) + '\\n'\n",
    "\n",
    "    # Write header to file.\n",
    "    with open(file, 'w') as f:\n",
    "        f.write(line)\n",
    "        \n",
    "def one_set_glv(input_pars, file='', N=1, S=None, model=MODEL.GLV, absent_init=False, use_lognormal_params=False):\n",
    "    \"\"\" Generates N time series of glv systems according to input parameters and writes summary\n",
    "    of the statistics of time series to file.\"\"\"\n",
    "\n",
    "    connectance, immigration, noise, int_strength, max_cap = input_pars\n",
    "\n",
    "    if 'MAX' in model.name and np.isinf(max_cap):\n",
    "        model = MODEL.GLV\n",
    "\n",
    "    # Reduce number of species (S_) until more than half of the solutions are good (not all 0 or NaN abundances).\n",
    "    S_ = S\n",
    "    Ngood_solutions = 0\n",
    "\n",
    "    while Ngood_solutions < N / 2 and S_ > 1:\n",
    "        Ngood_solutions = 0\n",
    "\n",
    "        line_stat = ''\n",
    "\n",
    "        for k in range(N):\n",
    "            # Set parameters.\n",
    "            params = random_parameter_set(S=S_,\n",
    "                                          minmigration=immigration, maxmigration=immigration, connectance=connectance,\n",
    "                                          minint=-int_strength, maxint=int_strength)\n",
    "            # Maximum capacity parameter.\n",
    "            if 'MAX' in model.name:\n",
    "                params['maximum_capacity'] = max_cap\n",
    "\n",
    "            # Noise parameters.\n",
    "            if noise_implementation == NOISE.LANGEVIN_LINEAR:\n",
    "                params['noise_linear'] = noise\n",
    "            elif noise_implementation == NOISE.LANGEVIN_CONSTANT:\n",
    "                params['noise_constant'] = noise\n",
    "\n",
    "            if use_lognormal_params:\n",
    "                # Set growth rate and self-interaction parameters to lognormally distributed parameters.\n",
    "                np.fill_diagonal(params['interaction_matrix'], -stats.lognorm.rvs(loc=0, s=1, size=S_))\n",
    "                params['growth_rate'] = stats.lognorm.rvs(loc=0, s=1, size=[S_, 1])\n",
    "\n",
    "            # Set initial condition\n",
    "            params['initial_condition'] = initial_condition(S_, model, max_cap, absent_init)\n",
    "            # Generate the time series and do the statistics\n",
    "            line_stat += line_statistics(params, model)\n",
    "            # Check whether solution is good (not all abundances 0 or NAN)\n",
    "            if np.any([number not in ['NAN', '0', ''] for number in line_stat.split(',')]):\n",
    "               Ngood_solutions += 1\n",
    "\n",
    "        # Reduce S_ for next iteration if there were not enough 'good' solutions\n",
    "        S_ = int(0.95 * S_) if S_ > 10 else (S_ - 1)\n",
    "\n",
    "    # Write results to file.\n",
    "    line = '%.3E,%.3E,%.3E,%.3E,%3E' % input_pars + line_stat + '\\n'\n",
    "    with open(file, 'a') as f:\n",
    "        f.write(line)\n",
    "\n",
    "def header_time_series(N, ibm=False):\n",
    "    \"\"\" Return string for header of statistical parameters of N time series.\"\"\"\n",
    "\n",
    "    line = \"\"\n",
    "\n",
    "    # Statistical parameters for one time series.\n",
    "    subline = 'number_%d,' \\\n",
    "              'variation_mean_%d,variation_std_%d,variation_min_%d,variation_max_%d,' \\\n",
    "              'variationnorm_mean_%d,variationnorm_std_%d,variationnorm_min_%d,variationnorm_max_%d,' \\\n",
    "              'JS_mean_%d,JS_std_%d,JS_min_%d,JS_max_%d,JS_stab_%d,' \\\n",
    "              'log_width_%d,log_loc_%d,log_scale_%d,log_stat_%d,log_pval_%d,' \\\n",
    "              'pareto_a_%d,pareto_loc_%d,pareto_scale_%d,pareto_stat_%d,pareto_pval_%d,' \\\n",
    "              'pow_a_%d,pow_loc_%d,pow_scale_%d,pow_stat_%d,pow_pval_%d,' \\\n",
    "              'tpow_a_%d,tpow_scale_%d,tpow_R_%d,tpow_p_%d,tpow_stat_%d,tpow_pval_%d,' \\\n",
    "              'exp_loc_%d,exp_scale_%d,exp_stat_%d,exp_pval_%d,' \\\n",
    "              'norm_loc_%d,norm_scale_%d,norm_stat_%d,norm_pval_%d'\n",
    "    Npars = 43 # number of paramters in line\n",
    "\n",
    "    # Add stability paramter if not for ibm.\n",
    "    if not ibm:\n",
    "        subline = ',stability_%d,' + subline\n",
    "        Npars += 1\n",
    "\n",
    "    # Add statistical parameters for number of time series N.\n",
    "    for i in range(1, N + 1):\n",
    "        line += subline % ((i,) * Npars)\n",
    "    return line\n",
    "\n",
    "def test_glv(file):\n",
    "    \n",
    "    int_strength = 0.5\n",
    "    noise = 0.5\n",
    "    max_cap = 100\n",
    "    N_repeats = 10\n",
    "    setup_glv(file, N=N_repeats)\n",
    "    if True: \n",
    "        for connectance in  np.array([0,0.1,0.2,0.3,0.4,0.5,.6,.7,.8,.9,1]):#[0,0.1,0.2,0.3,0.4,0.5,.6,.7,.8,.9,1][0,0.2,0.4,.6,.8,1]\n",
    "            for immigration in np.array([ 0.0,0.01,0.03162,0.1,0.3162,1.0,3.162,10.0]):#np.array([0,10**(-4),10**(-3),10**(-2),10**(-1)]):#[0,10**(-4),10**(-3),10**(-2),10**(-1)]\n",
    "                print('connectance ', connectance)\n",
    "                print('immigration ',immigration)\n",
    "                one_set_glv((connectance, immigration, noise, int_strength, max_cap), file=file, N=N_repeats, S=200, model=MODEL.MAX_IMMI)\n",
    "    if False:\n",
    "        connectance = 0.0\n",
    "        immigration = 0.0\n",
    "        for max_cap in  np.array([10,100,100,np.inf]):\n",
    "            for noise in np.array([0,0.2,0.4,0.6,1]):\n",
    "                print('max cap is ', max_cap)\n",
    "                print('noise is ',noise)\n",
    "                one_set_glv((connectance, immigration, noise, int_strength, max_cap), file=file, N=N_repeats, S=200, model=MODEL.MAX_IMMI)\n",
    "\n",
    "# Main function performs different tests\n",
    "# \n",
    "\n",
    "def main():\n",
    "    # test_absent_species_initial_condition('test_absent_species_initial_condition.csv')\n",
    "    test_glv('test_glv.csv')\n",
    "    #test_ibm('test_ibm.csv')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    threshold = 1e-6 #1e-8\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
